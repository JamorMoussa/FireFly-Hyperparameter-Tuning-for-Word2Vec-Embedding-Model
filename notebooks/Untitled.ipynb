{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db3124f-a3da-4abc-a0f6-f5ecfc3e125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faab7159-fa80-4332-8c53-96f40854a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireflyOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, func, dim, n_fireflies=20, alpha=0.5, beta0=1.0, gamma=1.0, lb=-10, ub=10, max_iter=100):\n",
    "        defaults = dict(func=func, dim=dim, n_fireflies=n_fireflies, alpha=alpha, beta0=beta0, gamma=gamma, lb=lb, ub=ub, max_iter=max_iter)\n",
    "        super(FireflyOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            func = group['func']\n",
    "            dim = group['dim']\n",
    "            n_fireflies = group['n_fireflies']\n",
    "            alpha = group['alpha']\n",
    "            beta0 = group['beta0']\n",
    "            gamma = group['gamma']\n",
    "            lb = group['lb']\n",
    "            ub = group['ub']\n",
    "            max_iter = group['max_iter']\n",
    "\n",
    "            # Initialize firefly positions\n",
    "            fireflies = lb + (ub - lb) * torch.rand((n_fireflies, dim), device=self.param_groups[0]['params'][0].device)\n",
    "            intensities = torch.zeros(n_fireflies, device=self.param_groups[0]['params'][0].device)\n",
    "\n",
    "            # Main optimization loop\n",
    "            for t in range(max_iter):\n",
    "                # Evaluate intensities\n",
    "                for i, param_group in enumerate(self.param_groups):\n",
    "                    for j, p in enumerate(param_group['params']):\n",
    "                        p.data += torch.rand_like(p.data) * 0.01  # Random update for demonstration purposes\n",
    "                        intensities[i] = func(p.data)\n",
    "\n",
    "                # Update firefly positions\n",
    "                for i in range(n_fireflies):\n",
    "                    for j in range(n_fireflies):\n",
    "                        if intensities[j] < intensities[i]:\n",
    "                            r = torch.norm(fireflies[i] - fireflies[j])\n",
    "                            beta = beta0 * math.exp(-gamma * r**2)\n",
    "                            fireflies[i] += beta * (fireflies[j] - fireflies[i]) + alpha * (torch.rand(dim) - 0.5)\n",
    "\n",
    "                            # Ensure new position is within bounds\n",
    "                            fireflies[i] = torch.clamp(fireflies[i], lb, ub)\n",
    "\n",
    "            # Update parameter values\n",
    "            for i, param_group in enumerate(self.param_groups):\n",
    "                for j, p in enumerate(param_group['params']):\n",
    "                    p.data = fireflies[i]\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ca7f2f-1c65-4002-8e1a-ca36fb4206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model and loss function\n",
    "model = nn.Linear(3, 1)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5440d926-8ff4-40c6-b836-87edb8957457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of your custom FireflyOptimizer\n",
    "optimizer = FireflyOptimizer(model.parameters(), lambda x: loss_func(model(inputs), targets), dim=3, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "424b16a3-a1b8-467b-9b15-762062d7e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(100, 3)\n",
    "targets = torch.mm(inputs, torch.Tensor([[1, 2, 3]]).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223e6085-eccb-4b2c-914d-6051cf04cbbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FireflyAlgorithm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Instantiate the FireflyAlgorithm optimizer\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m fa \u001b[38;5;241m=\u001b[39m \u001b[43mFireflyAlgorithm\u001b[49m(func, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m best_solution, best_fitness \u001b[38;5;241m=\u001b[39m fa\u001b[38;5;241m.\u001b[39moptimize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FireflyAlgorithm' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(100, 3)\n",
    "targets = torch.mm(inputs, torch.Tensor([[1, 2, 3]]).t())\n",
    "\n",
    "# Reshape targets to be a column vector\n",
    "targets = targets.view(-1, 1)\n",
    "\n",
    "# Instantiate the FireflyAlgorithm optimizer\n",
    "fa = FireflyAlgorithm(func, dim=3, max_iter=1000)\n",
    "\n",
    "# Optimize the model\n",
    "best_solution, best_fitness = fa.optimize()\n",
    "\n",
    "# Set the best solution as the weights of the linear regression model\n",
    "model.weight.data = torch.tensor(best_solution.reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d244f2-57cb-44a2-86cd-55a4129f86a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix, got 1-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, targets)\n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat2 must be a matrix, got 1-D tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for _ in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(model(inputs), targets)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcada77-93b2-4b34-9ba6-bba67a7800e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 6.3520, -5.3422,  5.2594], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4af29-f2cb-4266-952b-9a6dddd90f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
